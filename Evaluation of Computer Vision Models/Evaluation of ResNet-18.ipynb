{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We read the semantic representation from a trained network layer. \n",
    "#We choose ResNet-18 model (trained on the ImageNet dataset with 1000 categories and 1 million images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeRepresentationTensor(imageName,model,layer):\n",
    "    \n",
    "    \"\"\"Compute the tensor representation for the image receive as input \"\"\"\n",
    "    \n",
    "    \n",
    "    img = Image.open(imageName)\n",
    "    \n",
    "    #We prepare our image to be like the images ResNet 18 model was trained on.\n",
    "    #For this we scale it, normalize it and convert it to a tensor\n",
    "    img = img.convert(\"RGB\")\n",
    "    preprocess=transforms.Compose([   transforms.Resize((224, 224)),\n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "                                     ]\n",
    "                                 )\n",
    "    \n",
    "    #all above transformations apllied to the input image\n",
    "    #unsqueeze=>reshape the image from (3, 224, 224) to (1, 3, 224, 224). \n",
    "    #PyTorch expects a 4-dimensional input with the first dimension = to the number of samples.\n",
    "    imgTransformed = preprocess(img).unsqueeze(0)\n",
    "    \n",
    "    #Where we copy the avearge pool layer representation\n",
    "    features = []\n",
    "\n",
    "    # Define a function that will copy the output of a layer (see the above explanation for the parameters used)\n",
    "    def hook(m, i, o):\n",
    "        features.extend(o.view(o.size(0),-1).cpu().data)\n",
    "\n",
    "    #Attach the hook to our selected layer (average pool layer in this case)\n",
    "    h = layer.register_forward_hook(hook)\n",
    "    \n",
    "    #Run the model on the input image\n",
    "    model(imgTransformed )\n",
    "\n",
    "    #Detach the hook\n",
    "    h.remove()\n",
    "    plt.imgshow(features)\n",
    "    \n",
    "    # return the image representation on the selected layer\n",
    "    return features[0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_sim():\n",
    "    df = pd.DataFrame(columns=[\"word1\", \"word2\", \"SL\",\"ESL\", \"model\"])\n",
    "    data = pd.read_excel(\"Est-SimLex999.xlsx\")\n",
    "    data = data[(data[\"conc(w1)\"] >=4.8) & (data[\"conc(w2)\"]>=4.8)]\n",
    "    print(data.shape)\n",
    "    averages = []\n",
    "    simlex = []\n",
    "    rerate = []\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    \n",
    "    #look at the model\n",
    "    #print (model)\n",
    "    \n",
    "    # We select the layer we interested in, the average pool layer\n",
    "    layer = model._modules.get('avgpool')\n",
    "    \n",
    "    #check we've selected the right layer\n",
    "    #print (layer)\n",
    "    \n",
    "    #We must eliminate dropout during testing\n",
    "    model.eval()\n",
    "    for i, row in data.iterrows():\n",
    "        word1 = row[\"word 1\"].strip()\n",
    "        word2 = row[\"word 2\"].strip()\n",
    "        w1_images = os.listdir(\"F:\\\\db\\\\\"+word1)\n",
    "        w2_images = os.listdir(\"F:\\\\db\\\\\"+word2)\n",
    "        similarities = []\n",
    "        features = [computeRepresentationTensor(\"F:\\\\db\\\\\"+word2 + \"\\\\\"+ w2, model , layer) for w2 in w2_images]\n",
    "        for w1 in w1_images:\n",
    "            try:\n",
    "                features1 = computeRepresentationTensor(\"F:\\\\db\\\\\"+word1 + \"\\\\\"+w1, model, layer)\n",
    "                for  features2 in features:  \n",
    "                    cos = nn.CosineSimilarity(0)\n",
    "                    cosineSimValue = cos (features1, features2)\n",
    "                    similarities.append(cosineSimValue.item())\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        averageSimilarity = sum(similarities)/len(similarities)\n",
    "        df = df.append({\"word1\":word1, \"word2\":word2, \"SL\":row[\"SimLex999\"], \"ESL\":row[\"Average\"], \"model\":averageSimilarity}, \n",
    "                      ignore_index=True)\n",
    "\n",
    "        \n",
    "    df.to_excel(\"results_from_resnet.xlsx\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calc_sim()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
