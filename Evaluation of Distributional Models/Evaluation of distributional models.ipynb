{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating various pre-trained models on SimLex-999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file correlations between various pretrained models similarity and SimLex-999 similarity are calculated, also correlations between the models' similarity score and similarity attained from Estonian raters are calculated. \n",
    "<br> \n",
    "EstSimLex-999 data set is also filtered by POS and concreteness level and the correlations with these filtered datasets are also calculated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import gensim\n",
    "print(gensim.__version__) \n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau, linregress\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.wrappers import FastText\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining all the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, modelname, data, saved_correlations):\n",
    "    \"\"\"\n",
    "    first similarity between word pairs is calculated and then correlations \n",
    "    between model's similarity score and human scores is calculated\n",
    "    \"\"\"\n",
    "    \n",
    "    missing = 0\n",
    "    sims_from_model = pd.DataFrame(columns=[\"sõna1\", \"sõna2\", \"SimLex999\", \"similarity_from_model\", \"EstSimLex999\", \"POS\", \"conc(w1)\", \"conc(w2)\"])\n",
    "    for i, row in data.iterrows():\n",
    "        s1 = row[\"sõna 1\"]\n",
    "        s2 = row[\"sõna 2\"]\n",
    "        estsl = row[\"Average\"]\n",
    "        sl = row[\"SimLex999\"]\n",
    "        conc1 = row[\"conc(w1)\"]\n",
    "        conc2 = row[\"conc(w2)\"]\n",
    "        pos = row[\"POS\"]\n",
    "        if s1 in model and s2 in model: \n",
    "            similarity_from_model = model.similarity(s1, s2)\n",
    "            sims_from_model = sims_from_model.append({\"sõna1\":s1, \"sõna2\":s2, \"SimLex999\":sl, \"EstSimLex999\":estsl,\"similarity_from_model\":similarity_from_model, \"POS\":pos, \"conc(w1)\":conc1, \"conc(w2)\":conc2 }, ignore_index=True)\n",
    "            \n",
    "        else:\n",
    "            missing += 1\n",
    "\n",
    "    # filtering by POS (A-adjective, N-noun, V-verb, conc-concrete, abst-abstract, orig-original)\n",
    "    # saving results to the same dataframe    \n",
    "    saved_correlations = calc_correlations(sims_from_model, saved_correlations, modelname+\"_orig\", missing)\n",
    "    saved_correlations = calc_correlations(sims_from_model[sims_from_model[\"POS\"] == \"A\"], saved_correlations, modelname+\"_A\", \"-\")\n",
    "    saved_correlations = calc_correlations(sims_from_model[sims_from_model[\"POS\"] == \"N\"], saved_correlations, modelname+\"_N\", \"-\")\n",
    "    saved_correlations = calc_correlations(sims_from_model[sims_from_model[\"POS\"] == \"V\"], saved_correlations, modelname+\"_V\", \"-\")\n",
    "    saved_correlations = calc_correlations(sims_from_model.sort_values([\"conc(w1)\", \"conc(w2)\"], ascending=False)[:250], saved_correlations, modelname+\"_conc\", \"-\")\n",
    "    saved_correlations = calc_correlations(sims_from_model.sort_values([\"conc(w1)\", \"conc(w2)\"], ascending=True)[:250], saved_correlations, modelname+\"_abst\", \"-\")\n",
    "        \n",
    "    return saved_correlations\n",
    "                \n",
    "        \n",
    "def calc_correlations(sims_from_model, saved_correlations, name, missing):\n",
    "    \n",
    "    # calculating pearson, spearman, kendalltau correlations of model's similarity ans SimLex999 similarity scores\n",
    "    pearsonSL = round(pearsonr(sims_from_model.similarity_from_model, sims_from_model.SimLex999)[0],3)\n",
    "    spearmanSL = round(spearmanr(sims_from_model.similarity_from_model, sims_from_model.SimLex999)[0],3)\n",
    "    kendallSL = round(kendalltau(sims_from_model.similarity_from_model, sims_from_model.SimLex999)[0],3)\n",
    "    \n",
    "    # calculating pearson, spearman, kendalltau correlations of model's similarity and EstSimLex999 similarity scores\n",
    "    pearsonESL = round(pearsonr(sims_from_model.similarity_from_model, sims_from_model.EstSimLex999)[0],3)\n",
    "    spearmanESL = round(spearmanr(sims_from_model.similarity_from_model, sims_from_model.EstSimLex999)[0],3)\n",
    "    kendallESL = round(kendalltau(sims_from_model.similarity_from_model, sims_from_model.EstSimLex999)[0],3)\n",
    "    \n",
    "    \n",
    "    saved_correlations = saved_correlations.append({\"model\":name, \"SL_pearson\":pearsonSL, \"SL_spearman\":spearmanSL, \n",
    "                                                       \"SL_kendall\":kendallSL, \"ESL_pearson\":pearsonESL, \"ESL_spearman\":spearmanESL,\n",
    "                                                       \"ESL_kendall\":kendallESL, \"missing\":missing}, ignore_index=True)\n",
    "    \n",
    "    return saved_correlations\n",
    "\n",
    "    \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving EstSimLex-999 to dataframe and creating a new dataframe, where all the correlations will be saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"EstSimLex999.xlsx\")\n",
    "df = pd.DataFrame(columns=[\"model\", \"SL_pearson\", \"SL_spearman\", \"SL_kendall\", \"ESL_pearson\", \"ESL_spearman\", \"ESL_kendall\", \"missing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Facebook research fastText vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebook research fastText vectors for English and Estonian were downloaded from https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md\n",
    "These pre-trained vectors were trained using CBOW with position-weights, in dimension 300, character n-grams of length 5, window size 5 and 10 negaitves. \n",
    "Used similarity measure is cosine similarity. This aquired similarities are compared with the EstSimLex-999 and SimLex-999 ones and correlation between them is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading pretrained vectors\n",
    "# specify the path, where the vectors can be accessed\n",
    "path_to_model = 'F:\\models\\wiki.et.vec'\n",
    "\n",
    "wiki_model_est = KeyedVectors.load_word2vec_format(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluating model, saving correlations to dataframe\n",
    "correlations = evaluate(wiki_model_est, \"wiki_model_est\", data, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EstNLTK word2vec models\n",
    "\n",
    "EstNLTK models are trained with word2vec software, on an Estonian Reference corpus. Embeddings can be downloaded from here https://github.com/estnltk/word2vec-models. <br>\n",
    "Four of the models are trained with CBOW (two of them on lemmatized version of the corpus). <br>\n",
    "Other four of the models are trained with Skip-gram (two of them on lemmatized version of the corpus). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterating over all the models and evaluating them, saving results to the same dataframe\n",
    "estnltk_models = os.listdir(\"F:\\\\models\\\\estnltk models\\\\\")\n",
    "for model_name in estnltk_models:\n",
    "    path = \"F:\\\\models\\\\estnltk models\\\\\"+model_name\n",
    "    model = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "    correlations = evaluate(model, model_name, data, correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained word and multi-sense embeddings for Estonian\n",
    "Eleri Aedmaa's word and sense vectors can be downloaded from here https://github.com/eleriaedmaa/embeddings. \n",
    "<br>\n",
    "Description of the models can also be viewed from this GitHub repository. All the embeddings are trained on lemmatized etTenTen: Corpus of the Estonian Web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluating all the models (only the word vectors, not sense vectors), saving to the same dataframe\n",
    "models = os.listdir(\"F:\\models\\models\")\n",
    "for model_name in models: \n",
    "    path = \"F:\\models\\models\\\\\"+model_name+\"\\\\\"+\"ettenten.txt.word_vectors\"\n",
    "    model = KeyedVectors.load_word2vec_format(path)\n",
    "    correlations = evaluate(model, model_name, data, correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when all the models are evaluated and results are in the dataframe, let's save it to  ecxel file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlations.to_excel(\"all_correlations.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
